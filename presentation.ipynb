{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f3aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hermex_assistant_chatbot.py\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_azure_ai.chat_models import AzureAIChatCompletionsModel\n",
    "from langchain_azure_ai.embeddings import AzureAIEmbeddingsModel\n",
    "\n",
    "# from langchain\n",
    "import asyncio, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# loading AI models\n",
    "\n",
    "llm = AzureAIChatCompletionsModel(\n",
    "    model_name=\"Llama-3.3-70B-Instruct\",\n",
    "    endpoint=endpoint,\n",
    "    # api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "embed = AzureAIEmbeddingsModel(\n",
    "    model_name=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "# File path for persistent FAISS index\n",
    "FAISS_PATH = \"hermex_faiss_index\"\n",
    "\n",
    "# URLs to load\n",
    "page_urls = [\n",
    "    \"https://hermextravels.com/\",\n",
    "    \"https://hermextravels.com/features.html\",\n",
    "    \"https://hermextravels.com/contact.html\",\n",
    "    \"https://hermextravels.com/investors.html\",\n",
    "    \"https://hermextravels.com/investors.html#investment-tiers\"\n",
    "]\n",
    "\n",
    "\n",
    "# Setup or load FAISS vectorstore\n",
    "def setup_vectorstore():\n",
    "    if os.path.exists(FAISS_PATH):\n",
    "        print(\"üîÅ Loading FAISS index from disk...\")\n",
    "        return FAISS.load_local(FAISS_PATH, embed, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        print(\"üî® Creating FAISS index from webpages...\")\n",
    "        loader = WebBaseLoader(web_paths=page_urls)\n",
    "        docs = loader.load()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        chunks = splitter.split_documents(docs)\n",
    "        vectorstore = FAISS.from_documents(chunks, embed)\n",
    "        vectorstore.save_local(FAISS_PATH)\n",
    "        return vectorstore\n",
    "\n",
    "\n",
    "\n",
    "# The Hera Assistant\n",
    "class HermexAssistant:\n",
    "    def __init__(self)->None:\n",
    "        load_dotenv()\n",
    "        self.llm = llm\n",
    "        self.embedding_model = embed\n",
    "        self.retriever = setup_vectorstore().as_retriever(search_kwargs={\"k\": 2})\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            You are Hera, a professional and efficient travel assistant for Hermex Travels.\n",
    "            Your purpose is to provide accurate, concise, and helpful answers strictly based on the provided context.\n",
    "            Avoid speculation and only provide facts relevant to Hermex services and the travel/tourism industry.\n",
    "\n",
    "            Use the following context to answer the user's question. If the answer is not in the context, reply with:\n",
    "            \"I'm sorry, I do not have information on that at the moment.\"\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Answer as a knowledgeable, polite, and articulate HUMAN travel assistant.\n",
    "            \"\"\"\n",
    "        )\n",
    "        self.qa_chain = self._setup_qa_chain()\n",
    "        self.user_sessions: dict = {}\n",
    "\n",
    "\n",
    "    def _setup_qa_chain(self)-> RetrievalQA:\n",
    "        return RetrievalQA.from_chain_type(\n",
    "            llm=self.llm,\n",
    "            retriever=self.retriever,\n",
    "            return_source_documents=False,\n",
    "             chain_type=\"stuff\"\n",
    "        )\n",
    "\n",
    "    # chat endpoint\n",
    "    def answer_question(self, user_id: str, query: str) -> str:\n",
    "        if query.strip(\" \"):\n",
    "            return self._standard_answer(user_id, query)\n",
    "\n",
    "    # normal response\n",
    "    def _standard_answer(self, user_id: str, query: str)-> str:\n",
    "        if user_id not in self.user_sessions:\n",
    "            self.user_sessions[user_id] = []\n",
    "\n",
    "        result = self.qa_chain.invoke(query)['result']\n",
    "        self.user_sessions[user_id].append((query, result))\n",
    "        return result\n",
    "\n",
    "    # get user history\n",
    "    def get_chat_history(self, user_id: str):\n",
    "        return self.user_sessions.get(user_id, [])\n",
    "\n",
    "    # clear use history\n",
    "    def clear_chat_history(self, user_id: str):\n",
    "        if user_id in self.user_sessions:\n",
    "            del self.user_sessions[user_id]\n",
    "            return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b70cde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loading FAISS index from disk...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't know what Hermex Travels is. The provided context only mentions\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hera = HermexAssistant()\n",
    "hera.answer_question(\"user1\", \"What is Hermex Travels?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2afd0ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm an AI assistant, and I'm here to help answer your questions to\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hera.answer_question(\"user1\", \"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b045e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
